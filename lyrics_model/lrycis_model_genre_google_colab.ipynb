{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2706,
     "status": "ok",
     "timestamp": 1733681062091,
     "user": {
      "displayName": "John Mezzo",
      "userId": "06955463856500797133"
     },
     "user_tz": 300
    },
    "id": "_XwAYFvIMA--",
    "outputId": "ed5a2181-e2e2-457b-b115-6ac84387c641"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "                       id             artist                   name  \\\n",
      "0  6vNcgPTLPyXflD733MmkAO           Warpaint               Undertow   \n",
      "1  3ugQJQiDJwVKM8szrpAYNa  The Exploding Boy      Cracked / Reasons   \n",
      "2  5utkTv4TSvgh9fjG386a84           Sanctity    Beneath The Machine   \n",
      "3  48jyqLwgvWTQcJrlBB27nO        Gipsy Kings            Petite noya   \n",
      "4  5xmqcLBNjrzOIancAp3bfX        Saxon Shore  This Shameless Moment   \n",
      "\n",
      "                                album   type  genre  \\\n",
      "0                            The Fool  train   rock   \n",
      "1                                Four  train   rock   \n",
      "2                          Once Again  train   rock   \n",
      "3                    The Very Best Of  train  latin   \n",
      "4  The Exquisite Death of Saxon Shore  train   rock   \n",
      "\n",
      "                             subgenres lyrics  \n",
      "0                      rock---shoegaze    NaN  \n",
      "1   rock---goth rock, rock---post-punk    NaN  \n",
      "2  rock---heavy metal, rock---nu metal    NaN  \n",
      "3                     latin---flamenco    NaN  \n",
      "4    rock---post rock, rock---shoegaze    NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "# mount google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "train_path = '/content/drive/MyDrive/deep_learning/data/train.csv'\n",
    "test_path = '/content/drive/MyDrive/deep_learning/data/test.csv'\n",
    "\n",
    "test_df = pd.read_csv(test_path)\n",
    "train_df = pd.read_csv(train_path)\n",
    "\n",
    "\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 564,
     "status": "ok",
     "timestamp": 1733681065011,
     "user": {
      "displayName": "John Mezzo",
      "userId": "06955463856500797133"
     },
     "user_tz": 300
    },
    "id": "pYquR2j2MA_A",
    "outputId": "024f5106-bec8-4438-b4d5-acb5498979f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   genre lyrics\n",
      "0   rock    NaN\n",
      "1   rock    NaN\n",
      "2   rock    NaN\n",
      "3  latin    NaN\n",
      "4   rock    NaN\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df.drop(columns=['id', 'artist', 'name', 'album', 'type'])\n",
    "test_df = test_df.drop(columns=['id', 'artist', 'name', 'album', 'type'])\n",
    "\n",
    "train_df = train_df.drop(columns=[\"subgenres\"])\n",
    "test_df = test_df.drop(columns=[\"subgenres\"])\n",
    "\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 346,
     "status": "ok",
     "timestamp": 1733681066523,
     "user": {
      "displayName": "John Mezzo",
      "userId": "06955463856500797133"
     },
     "user_tz": 300
    },
    "id": "cAgwkrYYMA_B",
    "outputId": "b1be9f1c-b859-497d-f1cb-1902be013031"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         genre                                             lyrics\n",
      "5        blues  By lorries along sir John Rogerson's quay Mr B...\n",
      "6   electronic  \\r\\nBlue skies and green fields\\r\\nI'm thinkin...\n",
      "8         rock  Fly, fly high my Black Eagle\\r\\nLet golden thr...\n",
      "13     hip hop  Why is it ladies only out for money?\\r\\nBrothe...\n",
      "18  electronic   Like...\\r\\n Turn it on, light it up, we gon s...\n",
      "        genre                                             lyrics\n",
      "0  electronic  \\r\\nEveryday After Work\\r\\nI Go To A Book Stor...\n",
      "1  electronic  \\r\\nMy little girl, drive anywhere\\r\\nDo what ...\n",
      "2  electronic  \\r\\nI was trapped under concrete\\r\\nBuilt from...\n",
      "3  electronic  \\r\\nNa, na, na, na, na, na\\r\\nNa, na, na, na, ...\n",
      "4  electronic  :\\r\\nF-A-I-L-U-R-E\\r\\nWoo\\r\\n:\\r\\nWe might as ...\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df.dropna(subset=['lyrics'])\n",
    "test_df = test_df.dropna(subset=['lyrics'])\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 499,
     "status": "ok",
     "timestamp": 1733681069104,
     "user": {
      "displayName": "John Mezzo",
      "userId": "06955463856500797133"
     },
     "user_tz": 300
    },
    "id": "eZstE97qMA_C",
    "outputId": "00d50cf3-3527-4bfd-ffbe-c8a927bd5e67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blues' 'electronic' 'rock' 'hip hop' 'funk / soul' 'pop' 'latin' 'jazz'\n",
      " 'classical']\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "genres = train_df['genre'].unique()\n",
    "\n",
    "print(genres)\n",
    "print(len(genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 379,
     "status": "ok",
     "timestamp": 1733681071686,
     "user": {
      "displayName": "John Mezzo",
      "userId": "06955463856500797133"
     },
     "user_tz": 300
    },
    "id": "4aqSFyMcMA_C",
    "outputId": "823610eb-354f-46a5-d2d2-7f0bdd5d98b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'blues': 0, 'electronic': 1, 'rock': 2, 'hip hop': 3, 'funk / soul': 4, 'pop': 5, 'latin': 6, 'jazz': 7, 'classical': 8}\n",
      "    genre                                             lyrics\n",
      "5       0  By lorries along sir John Rogerson's quay Mr B...\n",
      "6       1  \\r\\nBlue skies and green fields\\r\\nI'm thinkin...\n",
      "8       2  Fly, fly high my Black Eagle\\r\\nLet golden thr...\n",
      "13      3  Why is it ladies only out for money?\\r\\nBrothe...\n",
      "18      1   Like...\\r\\n Turn it on, light it up, we gon s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-3512a6508137>:9: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_df['genre'] = train_df[\"genre\"].replace(label_dict)\n",
      "<ipython-input-18-3512a6508137>:10: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_df['genre'] = test_df[\"genre\"].replace(label_dict)\n"
     ]
    }
   ],
   "source": [
    "# Converting genres to numerical values\n",
    "label_dict = {}\n",
    "for index, possible_label in enumerate(genres):\n",
    "    label_dict[possible_label] = index\n",
    "label_dict\n",
    "\n",
    "print(label_dict)\n",
    "\n",
    "train_df['genre'] = train_df[\"genre\"].replace(label_dict)\n",
    "test_df['genre'] = test_df[\"genre\"].replace(label_dict)\n",
    "\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4485,
     "status": "ok",
     "timestamp": 1733681078410,
     "user": {
      "displayName": "John Mezzo",
      "userId": "06955463856500797133"
     },
     "user_tz": 300
    },
    "id": "mRlYm-nyMA_C",
    "outputId": "de4e3463-3cdd-4e67-bb70-770f46871777"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    genre                                             lyrics\n",
      "5       0  By lorries along sir John Rogersons quay Mr Bl...\n",
      "6       1  Blue skies and green fieldsIm thinking of the ...\n",
      "8       2  Fly fly high my Black EagleLet golden thread b...\n",
      "13      3  Why is it ladies only out for moneyBrothers on...\n",
      "18      1   Like Turn it on light it up we gon set this o...\n"
     ]
    }
   ],
   "source": [
    "# Remove special characters\n",
    "def remove_special_characters(text):\n",
    "    return re.sub(r'[^A-Za-z0-9 ]+', '', text)\n",
    "\n",
    "train_df['lyrics'] = train_df['lyrics'].apply(remove_special_characters)\n",
    "test_df['lyrics'] = test_df['lyrics'].apply(remove_special_characters)\n",
    "\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 45255,
     "status": "ok",
     "timestamp": 1733681128535,
     "user": {
      "displayName": "John Mezzo",
      "userId": "06955463856500797133"
     },
     "user_tz": 300
    },
    "id": "hbU77tKZMA_C"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "train_embeddings = tokenizer(train_df['lyrics'].tolist(), padding=True, truncation=True, return_tensors='pt')\n",
    "test_embeddings = tokenizer(test_df['lyrics'].tolist(), padding=True, truncation=True, return_tensors='pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 527,
     "status": "ok",
     "timestamp": 1733681135322,
     "user": {
      "displayName": "John Mezzo",
      "userId": "06955463856500797133"
     },
     "user_tz": 300
    },
    "id": "PYIazt45MA_D"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class LyricsDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        super().__init__()\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "\n",
    "train_labels = train_df[\"genre\"].values\n",
    "train_dataset = LyricsDataset(train_embeddings, train_labels)\n",
    "test_labels = test_df[\"genre\"].values\n",
    "test_dataset = LyricsDataset(test_embeddings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1005,
     "status": "ok",
     "timestamp": 1733681143244,
     "user": {
      "displayName": "John Mezzo",
      "userId": "06955463856500797133"
     },
     "user_tz": 300
    },
    "id": "Qp9oznk8MA_D",
    "outputId": "a6975b1c-f243-48ea-fca7-b9b8b2b3996f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "from torch import optim\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "num_epochs = 10\n",
    "num_classes = 9\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_classes)\n",
    "\n",
    "# (Reference for Sulumain)***\n",
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# # Load the saved model and tokenizer \n",
    "# model_path = \"path_to_saved_model\"\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir='/content/drive/MyDrive/deep_learning/lyrics_results',\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_gpu_eval_batch_size=8,\n",
    "    num_train_epochs=num_epochs,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_steps=400,               # log & save weights each logging_steps\n",
    "    save_steps=400,\n",
    "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3535898,
     "status": "ok",
     "timestamp": 1733684683284,
     "user": {
      "displayName": "John Mezzo",
      "userId": "06955463856500797133"
     },
     "user_tz": 300
    },
    "id": "t8TmzaC0MA_E",
    "outputId": "db9a7635-2430-49d3-8163-2ab8fed40b56"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ··········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20241208_180632-um5hhhee</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jmez64-worcester-polytechnic-institute/huggingface/runs/um5hhhee' target=\"_blank\">/content/drive/MyDrive/deep_learning/lyrics_results</a></strong> to <a href='https://wandb.ai/jmez64-worcester-polytechnic-institute/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jmez64-worcester-polytechnic-institute/huggingface' target=\"_blank\">https://wandb.ai/jmez64-worcester-polytechnic-institute/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jmez64-worcester-polytechnic-institute/huggingface/runs/um5hhhee' target=\"_blank\">https://wandb.ai/jmez64-worcester-polytechnic-institute/huggingface/runs/um5hhhee</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-83134c748885>:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4120' max='4120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4120/4120 58:03, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.773300</td>\n",
       "      <td>1.938927</td>\n",
       "      <td>0.316413</td>\n",
       "      <td>0.199688</td>\n",
       "      <td>0.184883</td>\n",
       "      <td>0.316413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.535800</td>\n",
       "      <td>1.690450</td>\n",
       "      <td>0.394247</td>\n",
       "      <td>0.359374</td>\n",
       "      <td>0.347459</td>\n",
       "      <td>0.394247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.308300</td>\n",
       "      <td>1.839203</td>\n",
       "      <td>0.389171</td>\n",
       "      <td>0.354987</td>\n",
       "      <td>0.380624</td>\n",
       "      <td>0.389171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.995400</td>\n",
       "      <td>2.051076</td>\n",
       "      <td>0.385787</td>\n",
       "      <td>0.361824</td>\n",
       "      <td>0.413946</td>\n",
       "      <td>0.385787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.689000</td>\n",
       "      <td>2.282301</td>\n",
       "      <td>0.367174</td>\n",
       "      <td>0.356193</td>\n",
       "      <td>0.401789</td>\n",
       "      <td>0.367174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.464000</td>\n",
       "      <td>2.428977</td>\n",
       "      <td>0.390863</td>\n",
       "      <td>0.382944</td>\n",
       "      <td>0.400156</td>\n",
       "      <td>0.390863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.300400</td>\n",
       "      <td>3.275451</td>\n",
       "      <td>0.367174</td>\n",
       "      <td>0.356367</td>\n",
       "      <td>0.407494</td>\n",
       "      <td>0.367174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.191100</td>\n",
       "      <td>3.547125</td>\n",
       "      <td>0.402707</td>\n",
       "      <td>0.394430</td>\n",
       "      <td>0.410571</td>\n",
       "      <td>0.402707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.125300</td>\n",
       "      <td>3.697867</td>\n",
       "      <td>0.390863</td>\n",
       "      <td>0.386480</td>\n",
       "      <td>0.398369</td>\n",
       "      <td>0.390863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.113800</td>\n",
       "      <td>3.767061</td>\n",
       "      <td>0.387479</td>\n",
       "      <td>0.385788</td>\n",
       "      <td>0.402648</td>\n",
       "      <td>0.387479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "<ipython-input-21-83134c748885>:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "<ipython-input-21-83134c748885>:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "<ipython-input-21-83134c748885>:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "<ipython-input-21-83134c748885>:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "<ipython-input-21-83134c748885>:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "<ipython-input-21-83134c748885>:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "<ipython-input-21-83134c748885>:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "<ipython-input-21-83134c748885>:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "<ipython-input-21-83134c748885>:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "<ipython-input-21-83134c748885>:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4120, training_loss=0.7300755195247317, metrics={'train_runtime': 3534.8508, 'train_samples_per_second': 9.304, 'train_steps_per_second': 1.166, 'total_flos': 8654266498775040.0, 'train_loss': 0.7300755195247317, 'epoch': 10.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 32721,
     "status": "ok",
     "timestamp": 1733684715615,
     "user": {
      "displayName": "John Mezzo",
      "userId": "06955463856500797133"
     },
     "user_tz": 300
    },
    "id": "Hp1--lq-MKPG"
   },
   "outputs": [],
   "source": [
    "model.save_pretrained('/content/drive/MyDrive/deep_learning/lyrics_caption_finetune_model')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1R6dudSd_d9O0w5KBHoF7yT67rU1wRxfQ",
     "timestamp": 1733686503858
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
