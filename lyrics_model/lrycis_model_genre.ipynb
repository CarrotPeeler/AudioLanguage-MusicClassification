{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       id             artist                   name  \\\n",
      "0  6vNcgPTLPyXflD733MmkAO           Warpaint               Undertow   \n",
      "1  3ugQJQiDJwVKM8szrpAYNa  The Exploding Boy      Cracked / Reasons   \n",
      "2  5utkTv4TSvgh9fjG386a84           Sanctity    Beneath The Machine   \n",
      "3  48jyqLwgvWTQcJrlBB27nO        Gipsy Kings            Petite noya   \n",
      "4  5xmqcLBNjrzOIancAp3bfX        Saxon Shore  This Shameless Moment   \n",
      "\n",
      "                                album   type  genre  \\\n",
      "0                            The Fool  train   rock   \n",
      "1                                Four  train   rock   \n",
      "2                          Once Again  train   rock   \n",
      "3                    The Very Best Of  train  latin   \n",
      "4  The Exquisite Death of Saxon Shore  train   rock   \n",
      "\n",
      "                             subgenres lyrics  \n",
      "0                      rock---shoegaze    NaN  \n",
      "1   rock---goth rock, rock---post-punk    NaN  \n",
      "2  rock---heavy metal, rock---nu metal    NaN  \n",
      "3                     latin---flamenco    NaN  \n",
      "4    rock---post rock, rock---shoegaze    NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "train_df = pd.read_csv('datasets\\\\annotations\\\\train.csv')\n",
    "test_df = pd.read_csv('datasets\\\\annotations\\\\test.csv')\n",
    "\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   genre lyrics\n",
      "0   rock    NaN\n",
      "1   rock    NaN\n",
      "2   rock    NaN\n",
      "3  latin    NaN\n",
      "4   rock    NaN\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df.drop(columns=['id', 'artist', 'name', 'album', 'type'])\n",
    "test_df = test_df.drop(columns=['id', 'artist', 'name', 'album', 'type'])\n",
    "\n",
    "train_df = train_df.drop(columns=[\"subgenres\"])\n",
    "test_df = test_df.drop(columns=[\"subgenres\"])\n",
    "\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         genre                                             lyrics\n",
      "5        blues  By lorries along sir John Rogerson's quay Mr B...\n",
      "6   electronic  \\r\\nBlue skies and green fields\\r\\nI'm thinkin...\n",
      "8         rock  Fly, fly high my Black Eagle\\r\\nLet golden thr...\n",
      "13     hip hop  Why is it ladies only out for money?\\r\\nBrothe...\n",
      "18  electronic   Like...\\r\\n Turn it on, light it up, we gon s...\n",
      "        genre                                             lyrics\n",
      "0  electronic  \\r\\nEveryday After Work\\r\\nI Go To A Book Stor...\n",
      "1  electronic  \\r\\nMy little girl, drive anywhere\\r\\nDo what ...\n",
      "2  electronic  \\r\\nI was trapped under concrete\\r\\nBuilt from...\n",
      "3  electronic  \\r\\nNa, na, na, na, na, na\\r\\nNa, na, na, na, ...\n",
      "4  electronic  :\\r\\nF-A-I-L-U-R-E\\r\\nWoo\\r\\n:\\r\\nWe might as ...\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df.dropna(subset=['lyrics'])\n",
    "test_df = test_df.dropna(subset=['lyrics'])\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blues' 'electronic' 'rock' 'hip hop' 'funk / soul' 'pop' 'latin' 'jazz'\n",
      " 'classical']\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "genres = train_df['genre'].unique()\n",
    "\n",
    "print(genres)\n",
    "print(len(genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'blues': 0, 'electronic': 1, 'rock': 2, 'hip hop': 3, 'funk / soul': 4, 'pop': 5, 'latin': 6, 'jazz': 7, 'classical': 8}\n",
      "    genre                                             lyrics\n",
      "5       0  By lorries along sir John Rogerson's quay Mr B...\n",
      "6       1  \\r\\nBlue skies and green fields\\r\\nI'm thinkin...\n",
      "8       2  Fly, fly high my Black Eagle\\r\\nLet golden thr...\n",
      "13      3  Why is it ladies only out for money?\\r\\nBrothe...\n",
      "18      1   Like...\\r\\n Turn it on, light it up, we gon s...\n"
     ]
    }
   ],
   "source": [
    "# Converting genres to numerical values\n",
    "label_dict = {}\n",
    "for index, possible_label in enumerate(genres):\n",
    "    label_dict[possible_label] = index\n",
    "label_dict\n",
    "\n",
    "print(label_dict)\n",
    "\n",
    "train_df['genre'] = train_df[\"genre\"].replace(label_dict)\n",
    "test_df['genre'] = test_df[\"genre\"].replace(label_dict)\n",
    "\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    genre                                             lyrics\n",
      "5       0  By lorries along sir John Rogersons quay Mr Bl...\n",
      "6       1  Blue skies and green fieldsIm thinking of the ...\n",
      "8       2  Fly fly high my Black EagleLet golden thread b...\n",
      "13      3  Why is it ladies only out for moneyBrothers on...\n",
      "18      1   Like Turn it on light it up we gon set this o...\n"
     ]
    }
   ],
   "source": [
    "# Remove special characters\n",
    "def remove_special_characters(text):\n",
    "    return re.sub(r'[^A-Za-z0-9 ]+', '', text)\n",
    "\n",
    "train_df['lyrics'] = train_df['lyrics'].apply(remove_special_characters)\n",
    "test_df['lyrics'] = test_df['lyrics'].apply(remove_special_characters)\n",
    "\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "train_embeddings = tokenizer(train_df['lyrics'].tolist(), padding=True, truncation=True, return_tensors='pt')\n",
    "test_embeddings = tokenizer(test_df['lyrics'].tolist(), padding=True, truncation=True, return_tensors='pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class LyricsDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        super().__init__()\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "\n",
    "train_labels = train_df[\"genre\"].values\n",
    "train_dataset = LyricsDataset(train_embeddings, train_labels)\n",
    "test_labels = test_df[\"genre\"].values\n",
    "test_dataset = LyricsDataset(test_embeddings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Python311\\Lib\\site-packages\\transformers\\training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "from torch import optim\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "num_epochs = 10\n",
    "num_classes = 9\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_classes)\n",
    "\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir='./lyrics_results',\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_gpu_eval_batch_size=8,\n",
    "    num_train_epochs=num_epochs,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_steps=400,               # log & save weights each logging_steps\n",
    "    save_steps=400,\n",
    "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps'   \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e31693d26e48419efda07831ce5cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_28536\\794704457.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7577, 'grad_norm': 6.282198429107666, 'learning_rate': 4.514563106796117e-05, 'epoch': 0.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21cb1254eb8e43568b21970fecc4b715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.0115902423858643, 'eval_accuracy': 0.2893401015228426, 'eval_f1': 0.20547277722553925, 'eval_precision': 0.2211280754261468, 'eval_recall': 0.2893401015228426, 'eval_runtime': 2127.1912, 'eval_samples_per_second': 0.278, 'eval_steps_per_second': 0.035, 'epoch': 0.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_28536\\794704457.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5902, 'grad_norm': 8.180068969726562, 'learning_rate': 4.029126213592233e-05, 'epoch': 1.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d73abbb3e047e2972c71d61951cfde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7999926805496216, 'eval_accuracy': 0.36209813874788493, 'eval_f1': 0.32106060873382875, 'eval_precision': 0.31911960845600956, 'eval_recall': 0.36209813874788493, 'eval_runtime': 389.74, 'eval_samples_per_second': 1.516, 'eval_steps_per_second': 0.19, 'epoch': 1.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_28536\\794704457.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
